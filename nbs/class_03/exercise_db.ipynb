{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class 3 - L1 and L2 regularization\n",
    "In our this lecture, we discussed some foundational concepts in data science, namely *overfitting*, the *bias-variance* trade-off, and *regularization*.\n",
    "Today, we will apply some of these concepts to interpret and improve the performance of our predictive models, focusing especially on regularization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AS usual, we will do all of this using `scikit-learn`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: As last week, under `nbs/class_03` you will find a notebook called `example.ipynb`, where I provide an example of how to run today's exercise on sample data.\n",
    "Some of it repeats things done as part of `class_02`, for the sake of completeness.\n",
    "But you can also:\n",
    "- just keep working on the same notebook as last week\n",
    "- work in a new notebook, but load data splits and models that have saved last week"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Today's exercise\n",
    "Gather in the same group as last week, and please go through the following steps:\n",
    "1. Look back at last week's notebook. If you have not applied any transformation to your input because you did not have time, spend some time thinking about whether it would make sense to do so. You can find relevant transformations in `scikit-learn`: https://scikit-learn.org/stable/modules/classes.html#module-sklearn.preprocessing. You will probably mostly be interested in `StandardScaler` and `MinMaxScaler`\n",
    "2. Look at the performance of the models you've fitted last week: what is the best model? Do you see any evidence of overfitting?\n",
    "3. Fit your maximal models with `Lasso` (https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html#sklearn.linear_model.Lasso) and `Ridge` (https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html#sklearn.linear_model.Ridge) estimators instead of `LinearRegression`. Make sure you look at the documentation to understand what these do. Fit multiple models with multiple values of alpha and store the outputs;\n",
    "4. Plot the performance of your models against your linear and KNN models from last week. Does the performance of the model on the validation set improve with regularization?\n",
    "5. For both `Lasso` and `Ridge` models, plot the value of the coefficients as a function of alpha. You can access the coefficients for a fitted `model` through `model.coef_`. What do you notice in terms of how LASSO versus Ridge behave? (Look at `example.ipynb` for inspiration)\n",
    "6. Finally, if any models are doing better than the linear model without regularization, select the best `Ridge` and the best `Lasso` model, and plot their coefficients, alongsize coefficients from the simple linear models. How do estimates change with regularization? Which values have changed the most? Do you have any hypothesis as to why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Once you have done this\n",
    "Please submit a pull request to my repository where, within `nbs/class_03/group-x` you have the notebook on which you have worked.\n",
    "If your notebook is the same as last week, please push that one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import pickle\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../class_02/data/train.pkl', 'rb') as file:\n",
    "    X_train, y_train = pickle.load(file)\n",
    "\n",
    "with open('../class_02/data/val.pkl', 'rb') as file:\n",
    "    X_val, y_val = pickle.load(file)\n",
    "\n",
    "with open('../class_02/data/test.pkl', 'rb') as file:\n",
    "    X_test, y_test = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit Lasso and Ridge regression on maximal models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare X\n",
    "X_train_sink = X_train.to_numpy()\n",
    "X_val_sink = X_val.to_numpy()\n",
    "X_test_sink = X_test.to_numpy()\n",
    "\n",
    "# function for fitting and evaluating lasso and ridge models\n",
    "def regularized_regression(X_train, y_train, X_val, y_val, X_test, y_test, alpha):\n",
    "\n",
    "    sink_lasso = Lasso(alpha = alpha)\n",
    "    sink_lasso.fit(X_train_sink, y_train)\n",
    "\n",
    "    sink_ridge = Ridge(alpha = alpha)\n",
    "    sink_ridge.fit(X_train_sink, y_train)\n",
    "\n",
    "    performance_alpha = []\n",
    "\n",
    "    # evaluate\n",
    "    for x,y,nsplit in zip([X_train, X_val, X_test],\n",
    "                        [y_train, y_val, y_test],\n",
    "                        ['train', 'val', 'test']):\n",
    "\n",
    "        preds_lasso = sink_lasso.predict(x)\n",
    "        r2_lasso = r2_score(y, preds_lasso)\n",
    "        rmse_lasso = np.sqrt(mean_squared_error(y, preds_lasso))\n",
    "\n",
    "        performance_alpha.append({'model': f'sink_lasso_{alpha}',\n",
    "                            'split': nsplit,\n",
    "                            'rmse': rmse_lasso.round(4),\n",
    "                            'r2': r2_lasso.round(4)})\n",
    "\n",
    "        preds_ridge = sink_ridge.predict(x)\n",
    "        r2_ridge = r2_score(y, preds_ridge)\n",
    "        rmse_ridge = np.sqrt(mean_squared_error(y, preds_ridge))\n",
    "\n",
    "        performance_alpha.append({'model': f'sink_ridge_{alpha}',\n",
    "                            'split': nsplit,\n",
    "                            'rmse': rmse_ridge.round(4),\n",
    "                            'r2': r2_ridge.round(4)})\n",
    "    \n",
    "    return performance_alpha\n",
    "\n",
    "# fit lasso and ridge models with different alpha values\n",
    "performance_lasso_ridge = []\n",
    "for alpha in [0.01, 0.1, 0.2, 0.5, 1.0, 20.0, 10.0, 100.0, 1000.0]:\n",
    "\n",
    "        performance_alpha = regularized_regression(X_train_sink, y_train, X_val_sink, y_val, X_test_sink, y_test, alpha=alpha)\n",
    "\n",
    "        performance_lasso_ridge.extend(performance_alpha)\n",
    "\n",
    "# save performances\n",
    "file_path = 'performances_lasso_ridge.txt'\n",
    "with open(file_path, 'w') as file:\n",
    "    json.dump(performance_lasso_ridge, file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine with performances from class 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
